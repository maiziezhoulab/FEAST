{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdea386f",
   "metadata": {},
   "source": [
    "# Tutorial: Spatial Interpolation with FEAST\n",
    "\n",
    "In this notebook, we will demonstrate how to use FEAST to interpolate between two spatial transcriptomics slices. We will reconstruct the 3D spatial expression patterns of genes by generating intermediate slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a777de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install FEAST if not already installed\n",
    "# !pip install FEAST-py\n",
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac1a5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 05:09:03.424784: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "<stdin>:1:10: fatal error: nvrtc.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "[KeOps] Warning : CUDA include path not found. Please set the CUDA_PATH or CUDA_HOME environment variable.\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "<stdin>:1:10: fatal error: nvrtc.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "[KeOps] Warning : CUDA include path not found. Please set the CUDA_PATH or CUDA_HOME environment variable.\n",
      "[KeOps] Compiling cuda jit compiler engine ... \n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "<stdin>:1:10: fatal error: cuda.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "<stdin>:1:10: fatal error: nvrtc.h: No such file or directory\n",
      "compilation terminated.\n",
      "\n",
      "[KeOps] Warning : CUDA include path not found. Please set the CUDA_PATH or CUDA_HOME environment variable.\n",
      "[KeOps] Compiling cuda jit compiler engine ... \n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/keopscore/binders/nvrtc/nvrtc_jit.cpp:16:10: fatal error: cuda.h: No such file or directory\n",
      "   16 | #include <cuda.h>\n",
      "      |          ^~~~~~~~\n",
      "compilation terminated.\n",
      "\n",
      "OK\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/keopscore/binders/nvrtc/nvrtc_jit.cpp:16:10: fatal error: cuda.h: No such file or directory\n",
      "   16 | #include <cuda.h>\n",
      "      |          ^~~~~~~~\n",
      "compilation terminated.\n",
      "\n",
      "OK\n",
      "[pyKeOps] Compiling nvrtc binder for python ... [pyKeOps] Compiling nvrtc binder for python ... \n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "In file included from /maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/pykeops/common/keops_io/pykeops_nvrtc.cpp:8:\n",
      "/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/keopscore/binders/nvrtc/keops_nvrtc.cpp:16:10: fatal error: cuda.h: No such file or directory\n",
      "   16 | #include <cuda.h>\n",
      "      |          ^~~~~~~~\n",
      "compilation terminated.\n",
      "\n",
      "OK\n",
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "In file included from /maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/pykeops/common/keops_io/pykeops_nvrtc.cpp:8:\n",
      "/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/keopscore/binders/nvrtc/keops_nvrtc.cpp:16:10: fatal error: cuda.h: No such file or directory\n",
      "   16 | #include <cuda.h>\n",
      "      |          ^~~~~~~~\n",
      "compilation terminated.\n",
      "\n",
      "OK\n",
      "Spateo version: 0.0.0\n",
      "Running on: cuda\n",
      "Spateo version: 0.0.0\n",
      "Running on: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "\n",
    "import spateo as st\n",
    "print(f\"Spateo version: {st.__version__}\")\n",
    "\n",
    "# Import FEAST interpolation modules\n",
    "from FEAST.interpolation import (\n",
    "    interpolate_slices,\n",
    "    InterpolationConfig\n",
    ")\n",
    "\n",
    "# Set figure params\n",
    "sc.settings.set_figure_params(dpi=100, facecolor=\"white\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Running on: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f91a76",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "We load the raw spatial transcriptomics slices and perform standard preprocessing (filtering, normalization, log-transformation, and HVG selection) to prepare them for alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b369ab6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading merfish_0610.h5ad...\n"
     ]
    },
    {
     "ename": "FileURLRetrievalError",
     "evalue": "Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=https://drive.google.com/uc?id=1lOQasZ9nxIDIZwlqEQDCBY0kJaA7GwZD\n\nbut Gdown can't. Please check connections and permissions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/gdown/download.py:267\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43mget_url_from_gdrive_confirmation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/gdown/download.py:55\u001b[0m, in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url:\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot retrieve the public link of the file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may need to change the permission to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnyone with the link\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or have had many accesses. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m: Cannot retrieve the public link of the file. You may need to change the permission to 'Anyone with the link', or have had many accesses. Check FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Use id parameter directly which is more robust than url\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         \u001b[43mgdown\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m slice1 \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerfish_0610.h5ad\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/maiziezhou_lab6/chen_yr/miniconda3/envs/simulator/lib/python3.9/site-packages/gdown/download.py:278\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m FileURLRetrievalError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m         message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve file url:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may still be able to access the file from the browser:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m             url_origin,\n\u001b[1;32m    277\u001b[0m         )\n\u001b[0;32m--> 278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FileURLRetrievalError(message)\n\u001b[1;32m    280\u001b[0m filename_from_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    281\u001b[0m last_modified_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tCannot retrieve the public link of the file. You may need to change\n\tthe permission to 'Anyone with the link', or have had many accesses.\n\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=https://drive.google.com/uc?id=1lOQasZ9nxIDIZwlqEQDCBY0kJaA7GwZD\n\nbut Gdown can't. Please check connections and permissions."
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "# Define paths and download data\n",
    "data_dir = \"./example_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Use file IDs directly, not URLs\n",
    "files = {\n",
    "    \"merfish_0610.h5ad\": \"1lOQasZ9nxIDIZwlqEQDCBY0kJaA7GwZD\",\n",
    "    \"merfish_0613.h5ad\": \"1L2oCrL23sjiOCdG2IOam7Q0_06bQQqWY\"\n",
    "}\n",
    "\n",
    "for filename, file_id in files.items():\n",
    "    output_path = os.path.join(data_dir, filename)\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        # Use id parameter directly which is more robust than url\n",
    "        gdown.download(id=file_id, output=output_path, quiet=False)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "slice1 = st.read(os.path.join(data_dir, \"merfish_0610.h5ad\"))\n",
    "slice2 = st.read(os.path.join(data_dir, \"merfish_0613.h5ad\"))\n",
    "\n",
    "def preprocess_slice(adata, label):\n",
    "    print(f\"\\nPreprocessing {label}...\")\n",
    "    # Filter\n",
    "    sc.pp.filter_cells(adata, min_genes=10)\n",
    "    sc.pp.filter_genes(adata, min_cells=3)\n",
    "    \n",
    "    # Save raw counts\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    \n",
    "    # Normalize and Log\n",
    "    sc.pp.normalize_total(adata)\n",
    "    sc.pp.log1p(adata)\n",
    "    \n",
    "    # HVGs\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
    "    print(f\"Shape after preprocessing: {adata.shape}\")\n",
    "    return adata\n",
    "\n",
    "slice1 = preprocess_slice(slice1, \"Slice 1\")\n",
    "slice2 = preprocess_slice(slice2, \"Slice 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574b88d",
   "metadata": {},
   "source": [
    "## 2. Spateo Alignment\n",
    "\n",
    "We use Spateo's `morpho_align` to align the two slices based on their spatial distribution and gene expression patterns. This generates an alignment matrix ($\\pi$) and transforms the spatial coordinates of the slices to a common coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99364afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing Group PCA...\")\n",
    "try:\n",
    "    st.align.group_pca([slice1, slice2], pca_key='X_pca')\n",
    "except Exception as e:\n",
    "    print(f\"Group PCA failed ({e}), falling back to individual PCA.\")\n",
    "    sc.pp.pca(slice1)\n",
    "    sc.pp.pca(slice2)\n",
    "\n",
    "print(\"\\nPerforming Morphological Alignment...\")\n",
    "aligned_slices, pis = st.align.morpho_align(\n",
    "    models=[slice1, slice2],\n",
    "    rep_layer='X_pca',\n",
    "    rep_field='obsm',\n",
    "    dissimilarity='cos',\n",
    "    verbose=True,\n",
    "    spatial_key='spatial',\n",
    "    key_added='align_spatial',\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "slice_ref1, slice_ref2 = aligned_slices\n",
    "alignment_pi = pis[0]\n",
    "\n",
    "# Convert alignment to numpy if needed\n",
    "if hasattr(alignment_pi, 'cpu'):\n",
    "    alignment = alignment_pi.cpu().numpy()\n",
    "else:\n",
    "    alignment = np.array(alignment_pi)\n",
    "\n",
    "print(f\"\\nAlignment complete.\")\n",
    "print(f\"Alignment matrix shape: {alignment.shape}\")\n",
    "\n",
    "# Update spatial coordinates in the objects to use the aligned coordinates\n",
    "# Spateo stores aligned coordinates in obsm['align_spatial_rigid'] or similar depending on mode\n",
    "# But morpho_align with key_added='align_spatial' usually adds 'align_spatial' and 'align_spatial_rigid'\n",
    "# We will use 'align_spatial_rigid' for rigid alignment visualization if available, or 'align_spatial'\n",
    "if 'align_spatial_rigid' in slice_ref1.obsm:\n",
    "    slice_ref1.obsm['spatial'] = slice_ref1.obsm['align_spatial_rigid']\n",
    "    slice_ref2.obsm['spatial'] = slice_ref2.obsm['align_spatial_rigid']\n",
    "elif 'align_spatial' in slice_ref1.obsm:\n",
    "    slice_ref1.obsm['spatial'] = slice_ref1.obsm['align_spatial']\n",
    "    slice_ref2.obsm['spatial'] = slice_ref2.obsm['align_spatial']\n",
    "\n",
    "print(\"Spatial coordinates updated to aligned positions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cadb6",
   "metadata": {},
   "source": [
    "## 3. Prepare for Interpolation\n",
    "\n",
    "We ensure that both slices have the exact same set of genes and are properly normalized for the interpolation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33861907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common genes\n",
    "common_genes = list(set(slice_ref1.var_names) & set(slice_ref2.var_names))\n",
    "print(f\"Common genes: {len(common_genes)}\")\n",
    "\n",
    "# Subset to common genes\n",
    "slice_ref1 = slice_ref1[:, common_genes].copy()\n",
    "slice_ref2 = slice_ref2[:, common_genes].copy()\n",
    "\n",
    "# Verify counts layer exists\n",
    "if 'counts' not in slice_ref1.layers:\n",
    "    print(\"Warning: 'counts' layer missing in Slice 1\")\n",
    "if 'counts' not in slice_ref2.layers:\n",
    "    print(\"Warning: 'counts' layer missing in Slice 2\")\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "print(f\"Final Slice 1 shape: {slice_ref1.shape}\")\n",
    "print(f\"Final Slice 2 shape: {slice_ref2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdd9b79",
   "metadata": {},
   "source": [
    "## 4. Run Interpolation\n",
    "\n",
    "We will generate intermediate slices between the two reference slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa044dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "n_slices = 5  # Number of intermediate slices\n",
    "t_values = np.linspace(0, 1, n_slices + 2)[1:-1]\n",
    "\n",
    "# Store all slices\n",
    "all_slices = []\n",
    "slice_metadata = []\n",
    "\n",
    "# Add Reference 1\n",
    "slice_ref1.obs['slice_type'] = 'reference'\n",
    "all_slices.append(slice_ref1)\n",
    "slice_metadata.append({'type': 'reference', 't': 0.0, 'z': 0.0})\n",
    "\n",
    "# Run Interpolation Loop\n",
    "print(\"Starting interpolation...\")\n",
    "for i, t in enumerate(t_values):\n",
    "    print(f\"Generating slice {i+1}/{len(t_values)} at t={t:.2f}...\")\n",
    "    \n",
    "    # Configure interpolation parameters\n",
    "    config = InterpolationConfig(\n",
    "        t=t,\n",
    "        use_normalized=True,\n",
    "        ot_method='sinkhorn',\n",
    "        ot_regularization=0.05,  # Tuned parameter\n",
    "        feature_weights={'mean': 3.0, 'variance': 1.0, 'zero_prop': 1.0}, # Tuned weights\n",
    "        sigma=1.0,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Interpolate\n",
    "    interpolated_slice = interpolate_slices(\n",
    "        adata1=slice_ref1,\n",
    "        adata2=slice_ref2,\n",
    "        alignment_matrix=alignment,\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    interpolated_slice.obs['slice_type'] = 'interpolated'\n",
    "    all_slices.append(interpolated_slice)\n",
    "    slice_metadata.append({'type': 'interpolated', 't': t, 'z': t * 100.0})\n",
    "\n",
    "# Add Reference 2\n",
    "slice_ref2.obs['slice_type'] = 'reference'\n",
    "all_slices.append(slice_ref2)\n",
    "slice_metadata.append({'type': 'reference', 't': 1.0, 'z': 100.0})\n",
    "\n",
    "print(f\"Interpolation complete. Total slices: {len(all_slices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc48b6e",
   "metadata": {},
   "source": [
    "## 5. Visualization\n",
    "\n",
    "We will visualize the 3D spatial expression of specific genes: **Chat** and **Dlk1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe93c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gene_3d(all_slices, slice_metadata, gene_name):\n",
    "    \"\"\"Plot a single gene in 3D across all slices.\"\"\"\n",
    "    if gene_name not in all_slices[0].var_names:\n",
    "        print(f\"Gene {gene_name} not found in dataset.\")\n",
    "        return\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    for slice_data, metadata in zip(all_slices, slice_metadata):\n",
    "        # Get expression\n",
    "        gene_idx = list(slice_data.var_names).index(gene_name)\n",
    "        X = slice_data.X.toarray() if hasattr(slice_data.X, 'toarray') else slice_data.X\n",
    "        expr = X[:, gene_idx]\n",
    "        \n",
    "        # Get coordinates\n",
    "        if 'spatial' in slice_data.obsm:\n",
    "            coords = slice_data.obsm['spatial']\n",
    "            z = np.full(len(coords), metadata['z'])\n",
    "            \n",
    "            # Style based on type\n",
    "            alpha = 0.4 if metadata['type'] == 'reference' else 0.2\n",
    "            size = 15 if metadata['type'] == 'reference' else 10\n",
    "            \n",
    "            p = ax.scatter(coords[:, 0], coords[:, 1], z, c=expr, cmap='viridis', \n",
    "                          s=size, alpha=alpha, linewidth=0)\n",
    "            \n",
    "    ax.set_title(f\"3D Expression: {gene_name}\")\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z (Depth)\")\n",
    "    plt.colorbar(p, label='Expression', shrink=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Plot specific genes\n",
    "plot_gene_3d(all_slices, slice_metadata, \"Chat\")\n",
    "plot_gene_3d(all_slices, slice_metadata, \"Dlk1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e3c835",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "\n",
    "We evaluate the quality of interpolation using the **Gene Continuity Score**. This metric measures how smoothly gene expression changes across the interpolated Z-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa1e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_continuity(all_slices, slice_metadata, gene_name):\n",
    "    \"\"\"Calculate continuity score for a gene.\"\"\"\n",
    "    means = []\n",
    "    for slice_data in all_slices:\n",
    "        if gene_name in slice_data.var_names:\n",
    "            gene_idx = list(slice_data.var_names).index(gene_name)\n",
    "            X = slice_data.X.toarray() if hasattr(slice_data.X, 'toarray') else slice_data.X\n",
    "            means.append(X[:, gene_idx].mean())\n",
    "            \n",
    "    means = np.array(means)\n",
    "    if len(means) < 2 or np.mean(means) == 0:\n",
    "        return 0.0\n",
    "        \n",
    "    # Continuity = 1 - (std of differences / mean expression)\n",
    "    score = 1.0 - np.std(np.diff(means)) / np.mean(means)\n",
    "    return score, means\n",
    "\n",
    "# Calculate for Chat and Dlk1\n",
    "genes_to_check = [\"Chat\", \"Dlk1\"]\n",
    "\n",
    "print(\"Interpolation Performance (Continuity Score):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for gene in genes_to_check:\n",
    "    score, means = calculate_continuity(all_slices, slice_metadata, gene)\n",
    "    print(f\"{gene}: {score:.4f}\")\n",
    "    \n",
    "    # Optional: Plot the mean expression trajectory\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    z_vals = [m['z'] for m in slice_metadata]\n",
    "    plt.plot(z_vals, means, 'o-', label=gene)\n",
    "    plt.title(f\"{gene} Expression Trajectory\")\n",
    "    plt.xlabel(\"Z Position\")\n",
    "    plt.ylabel(\"Mean Expression\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simulator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
